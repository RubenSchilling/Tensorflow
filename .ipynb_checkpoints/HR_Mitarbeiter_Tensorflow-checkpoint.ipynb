{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mit diesem neuronalen Netz, soll ermittelt werden ob ein Mitarbeiter, anhand von einigen Faktoren, das Unternehmen verlassen wird. Dazu wurde ein Datensatz mit 15000 HR Daten ausgewertet. Folgende Faktoren sind ermittelt worden:\n",
    "Zufriedenheit (%)\n",
    "letzte Evaluation (%)\n",
    "Anzahl der Projekte (Zahl)\n",
    "durchschnittliche monatliche Arbeitsstunden (Stunden)\n",
    "Betriebszugehörigkeit (Jahre)\n",
    "Arbeitsunfall (ja/nein)\n",
    "Beförderung in den letzten 5 Jahren (ja/nein)\n",
    "Abteilung (String)\t\n",
    "Gehalt (low/medium/high)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import der benötigten Frameworks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#einlesen der Daten in ein Pandas Datenframe\n",
    "df = pd.read_csv(\"datasets/HR_comma_sep.csv\")\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Zuweisung von numerischen Werten für die Abteilungen, für ein einfacheres Datenhandling\n",
    "mymap = {'accounting':1,'hr':2,'IT':3, 'management': 4 ,'marketing':3, 'product_mng' :5 , \n",
    "         'RandD':6,'sales':7,'support':8,'technical':9,}\n",
    "\n",
    "dfh =df.applymap(lambda s: mymap.get(s) if s in mymap else s)\n",
    "\n",
    "dfh.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Zuweisung von numerischen Werten für das Gehalt, für ein einfacheres Datenhandling#\n",
    "mymap = {'low':1,'medium':2,'high':3}\n",
    "\n",
    "dfh1 =dfh.applymap(lambda s: mymap.get(s) if s in mymap else s)\n",
    "\n",
    "dfh1.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Umsortierung der Spalten um die Daten für Tensorflow aufzubereiten\n",
    "cols = dfh1.columns.tolist()\n",
    "cols.insert(9, cols.pop(cols.index('left')))\n",
    "dfh1 = dfh1.reindex(columns= cols)\n",
    "dfh1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Übersicht über die Verteilung der Zielwerte\n",
    "y = dfh1['left'].values\n",
    "plt.hist(y, bins=50)\n",
    "plt.xlabel('Zielwert')\n",
    "plt.ylabel('Anzahl')\n",
    "plt.title('Verteilung der Zielwerte')\n",
    "print('Target value min {0:.3f} max {1:.3f} mean {2:.3f} std {3:.3f}'.format(np.min(y), np.max(y), np.mean(y), np.std(y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Übersicht über die Verteilung der einzelnen Atrribute des Datensatzes\n",
    "F_cols = [col for col in dfh1.columns]\n",
    "fig = plt.figure(figsize=(25, 25))\n",
    "plt_count = 0\n",
    "for col in F_cols:\n",
    "    plt_count += 1\n",
    "    plt.subplot(9, 3, plt_count) \n",
    "    plt.hist(dfh1[col].values, 50)\n",
    "    plt.title(\"Verteilung: \"+col)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Aufteilung in ein Trainings- und ein Testset mit der split Funktion von sklearn\n",
    "train_set, test_set = train_test_split(dfh1, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Abspeichern der Pandas Dataframes in CSV Dateien\n",
    "train_set.to_csv(\"train.csv\", header=None, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set.to_csv(\"test.csv\", header=None, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Laden der CSV Dateien in Tensorflow (hier wurden vorbereitete CSV Dateien genutzt)\n",
    "training_set = tf.contrib.learn.datasets.base.load_csv_with_header(\n",
    "    filename='train_prepared.csv',\n",
    "    target_dtype=np.int,\n",
    "    features_dtype=np.float32)\n",
    "\n",
    "testing_set = tf.contrib.learn.datasets.base.load_csv_with_header(\n",
    "    filename='test_prepared.csv',\n",
    "    target_dtype=np.int,\n",
    "    features_dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Trainingsinputs definieren\n",
    "def get_train_inputs():\n",
    "    x = tf.constant(training_set.data)\n",
    "    y = tf.constant(training_set.target)\n",
    "    #  y = tf.summary.scalar(, training_set.target)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Testinputs definieren\n",
    "def get_test_inputs():\n",
    "    x = tf.constant(testing_set.data)\n",
    "    y = tf.constant(testing_set.target)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auslesen der Trainingsdaten\n",
    "training_set.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aufbau eines Color Dictionarys um den Scatter Plot visualisieren zu können\n",
    "colorDict = [\"blue\", \"red\"]\n",
    "colorDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Zuweisung der Farben zu den Target Werten\n",
    "# Blau = Mitarbeiter bleibt\n",
    "# Rot =Mitarbeiter verlässt das Unternehmen\n",
    "colors = []\n",
    "for target in training_set.target:\n",
    "    colors.append(colorDict[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Daten für die Visualisierung definieren\n",
    "dataX0 = training_set.data[:,0]\n",
    "dataX1 = training_set.data[:,1]\n",
    "dataX2 = training_set.data[:,2]\n",
    "dataX3 = training_set.data[:,3]\n",
    "dataX4 = training_set.data[:,4]\n",
    "dataX5 = training_set.data[:,5]\n",
    "dataX6 = training_set.data[:,6]\n",
    "dataX7 = training_set.data[:,7]\n",
    "dataX8 = training_set.data[:,8]\n",
    "\n",
    "dataY = training_set.target[:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scatterplots\n",
    "beispielhaft wurden hier 2 Scatterplots gezeichnet um Abhängigkeiten zwischen den Attributen erkennen zu können.\n",
    "Im ersten Scatterplot wurden die monatlichen Stunden mit der Zufriedenheit verglichen, hierbei fällt auf, dass sich vor allem zwei Cluster bilden bei Leuten, welche das Unternehmen verlassen.\n",
    "1. Mitarbeiter, welche sehr wenig arbeiten und dabei unzufrieden sind\n",
    "2. Mitarbeiter mit einer sehr hohen Zufriedenheit und Arbeitsleistung, diese werden womöglich abgeworben\n",
    "\n",
    "Der zweite Scatterplot zeigt die Zufriedenheit in Abhängigkeit mit der letzten Mitarbeiterevaluation, hier finden sich drei Cluster\n",
    "1. Hohe Zufriedenheit, gute Evaluation (Mitarbeiter werden womöglich abgeworben\n",
    "2. Niedrige Zufriedenheit, gute Evaluation (Mitarbeiter sind unzufrieden und verlassen das Unternehmen)\n",
    "3. Niedrige Zufriedenheit, schlechte Evaluation (Momöglich unmotivierte Minderleister, welche man garnicht halten möchte)\n",
    "\n",
    "In dieser Form sind noch viele Scatterplots möglich zu visualisieren. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(dataX3, dataX1, c=colors, s=1) # , cmap=plt.cm.cool)\n",
    "plt.xlabel('Monatliche Stunden')\n",
    "plt.ylabel('Zufriedenheit')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(dataX1, dataX0, c=colors, s=1) # , cmap=plt.cm.cool)\n",
    "plt.xlabel('Letzte Evaluation')\n",
    "plt.ylabel('Zufriedenheit')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Alle Spalten besitzen echte Daten, und die Dimension beträgt 9\n",
    "feature_columns = [tf.contrib.layers.real_valued_column(\"\", dimension=9)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ein Validation Monitor wurde erstellt der beim Training des Classifiers eine Log Datei erstellt,\n",
    "#welche später ausgewertet werden kann, dies erhöht jedoch die Berechnungszeit stark!\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "validation_monitor = tf.contrib.learn.monitors.ValidationMonitor(\n",
    "    training_set.data,\n",
    "    training_set.target,\n",
    "    every_n_steps=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanziierung des Classifieres, hier wurden 4 Ebenen gewählt mit jeweils 10, 50, 100, 10 Neuronen, dies ergab in Tests das beste Ergebnis\n",
    "classifier = tf.contrib.learn.DNNClassifier(feature_columns=feature_columns,\n",
    "                                            hidden_units=[10, 50, 100, 10],\n",
    "                                            n_classes=2,\n",
    "                                            model_dir=\"/tmp/HR_model_final\",\n",
    "                                           config=tf.contrib.learn.RunConfig(save_checkpoints_secs=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Das Trainieren des Classifiers mit Hilfe der Traingsdaten, es wurden 100.000 Schritte gewählt, \n",
    "# damit konnte eine Accuracy von 96,XX% erreicht werden\n",
    "classifier.fit(input_fn=get_train_inputs, steps=100000, monitors=[validation_monitor])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss function mit TensorBoard\n",
    "Um die Loss Function sichtbar zu machen muss im Terminal folgender Befehl ausgeführt werden:\n",
    "\n",
    "--logdir=/tmp/HR_model_final\n",
    "\n",
    "Es wird nun eine Tensorboard Seite erstellt und ein Link generiert auf dem diese angesehen werden kann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ausgabe der Genuigkeit unseres erstellten Classifieres mit Hilfe der Test Daten\n",
    "accuracy_score = classifier.evaluate(input_fn=get_test_inputs, steps=1)[\"accuracy\"]\n",
    "print(\"\\nTest Accuracy: {0:.1f}%\\n\".format(100*accuracy_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Klassifizierung von zwei neuen, selbst ausgedachten Mitarbeitern\n",
    "def new_samples():\n",
    "  return np.array(\n",
    "    [[0.7, 0.47, 2, 154, 3, 0, 0, 7, 1],\n",
    "     [0.59, 0.55, 6, 250, 5, 0, 0, 6, 2]], dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = list(classifier.predict_classes(input_fn=new_samples))\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Einordnung der Mitarbeiter in dem vorher schon gezeigten Scatter Plot\n",
    "plt.scatter(dataX3, dataX1, c=colors, s=1)\n",
    "plt.scatter(new_samples()[1,3], new_samples()[1,0], c=[\"black\"], marker=\"x\", s=100)\n",
    "plt.scatter(new_samples()[0,3], new_samples()[0,0], c=[\"black\"], marker=\"x\", s=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
